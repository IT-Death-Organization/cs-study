# Day 1: 배열(Array)과 리스트(List)
> 📅 2025.02.13 | 📁 Week 1

---

## 🧠 학습 질문

- [x] 배열의 접근이 O(1)인 이유를 메모리 주소 계산 관점에서 설명하면?
- [x] 배열의 중간 삽입/삭제가 O(n)인 이유는?
- [x] 동적 배열이 크기가 가득 찼을 때 2배로 확장하는 이유는?
- [x] 재할당 시 기존 요소들을 복사하는데 왜 amortized O(1)이 되는가?
- [x] Cache locality 관점에서 배열이 연결 리스트보다 유리한 이유는?
- [x] 연결 리스트와 배열 중 어떤 상황에서 무엇을 선택해야 하는가?

---

## Q1. 배열의 접근이 O(1)인 이유를 메모리 주소 계산 관점에서 설명하면?

[답변]
메모리 상에서 배열을 나타내는 변수는 배열의 시작 주소를 가지고 있다. 배열의 요소에는 인덱스로 접근하기 때문에, 배열의 시작 주소와 인덱스, 자료형의 크기를 바탕으로 해당 요소가 위치한 주소를 계산할 수 있고, 이를 이용해 요소에 바로 접근할 수 있기 때문에 O(1)이다.

[보완]
* '바로 접근'
    - 주소 계산 + 메모리 접근 한 번만에 요소 접근 가능
* 연속 배치 + 고정 크기 원소 + base address

[정리]
배열이 시작 주소(base)를 알고 있고, i번째 원소 주로를 base + i * 원소크기로 즉시 계산 -> 한 번의 메모리 접근으로 읽기/쓰기 가능 -> O(1)

---

## Q2. 배열의 중간 삽입/삭제가 O(n)인 이유는?

[답변]
배열은 연속된 메모리를 가지고 있기 때문에 중간에 삽입하려면, 해당 위치 이후에 위치해있던 요소들은 한 칸씩 뒤로 밀리고, 밀리는 요소의 최대 개수가 배열 요소의 개수이므로 O(n)이다. 마찬가지로 삭제는, 해당 위치 이후의 요소들이 한 칸씩 앞으로 당겨지기 때문에 O(n)이다.

[보완]
* 핵심은 '인덱스 기반의 순서를 유지' -> 빈 칸/중복을 허용 X -> 이동 발생
* 최악 O(n), 평균도 대략 O(n)

[정리]
배열은 순서를 유지하는 '연속 구조'라서 중간 삽입/삭제 시 뒤쪽 원소들을 선형으로 이동해야 하므로 O(n)

---

## Q3. 동적 배열이 크기가 가득 찼을 때 2배로 확장하는 이유는?

[답변]
동적 배열은 배열에 추가되는 요소에 따라 공간을 확장해야 하는데, 이때 너무 작은 크기로 확장하면 확장이 잦아 비효율적이고, 너무 큰 크기로 확장하면 추가되는 요소에 비해 낭비되는 공간이 많으므로, 2배로 확장하는 것이 가장 적당하다.

[보완]
* 핵심은 재할당 빈도를 기하급수적으로 줄이려는 전략
* 재할당 빈도 vs 메모리 낭비
    - 용량을 매번 +1 또는 +k로 늘리면, 복사가 자주 발생 -> 전체가 O(n²)까지 커질 수 있음
    - 2배처럼 기하급수적 확장 -> 재할당 횟수는 대략 log₂n번으로 줄음 -> 총 복사량도 선형 수준으로 제한
    - 2배는 재할당 빈도를 줄이는 대신 최대 약 50%까지 여유 공간이 생길 수 있음
    - 더 작은 배수는 메모리 낭비를 줄이지만 재할당이 더 잦아짐

[정리]
### 재할당 크기를 선형적으로 증가(C0: 초기 용량, N: 최종 원소 수)
* 용량: C0 -> C0+k -> C0+2k -> C0+3k -> ...
* C0+mk >= N이 되는 최소 m이 재할당 횟수
* m = (N-C0)/k
    - N에 비례

### 재할당 크기를 기하급수적으로 증가(C0: 초기 용량, N: 최종 원소 수)
* 용량: C0 -> k*C0 -> k*k*C0 -> k*k*k*C0 -> ...
* C0 * k<sup>m</sup> >= N이 되는 최소 m이 재할당 횟수
* m = log<sub>k</sub>(N/C0)
    - logN에 비례

=> 재할당 빈도를 제한하기 위함. '2배'인 이유는 메모리 낭비의 상한을 두기 위함

---

## Q4. 재할당 시 기존 요소들을 복사하는데 왜 amortized O(1)이 되는가?

[답변]
몰랐던 사실이지만 유추해보자면 배열은 결국 연속된 공간에 있으므로 배열 전체를 하나의 데이터로 보고 한 번에 복사하지 않을까?

[오류]
* “배열 전체를 하나의 데이터로 보고 한 번에 복사”는 일반적으로 부정확 (저수준에서는 memcpy 같은 블록 복사가 가능할 때도 있지만, 개념적으로는 원소 수만큼 이동 비용이 든다)
* 핵심은 “한 번에 복사해서 빠르다”가 아니라, 비싼 복사가 가끔만 발생하도록 설계되어 전체 평균 비용이 상수로 수렴한다는 점

[보완]
amortized: 평균 상환(분할) 비용 -> 여러 번의 연산을 묶어서 총비용을 나눈 1회당 평균 비용

[정리]
* 복사량: 1 + 2 + 3 + ... + N/2 < N => O(N)
* 요소 삽입 횟수: N번
=> O(N) / N -> amortized O(1)

"요소 삽입 연산 횟수에 대한 복사 비용"

---

## Q5. Cache locality 관점에서 배열이 연결 리스트보다 유리한 이유는?

[답변]
배열은 연속된 공간에 여러 요소들이 배치해 있기 때문에, 캐시가 공간 지역성 측면에서 적중률이 더 좋을 것 같다.

[보완]
* Cache locality
    - CPU 캐시가 '가까운 데이터'를 잘 맞히도록 만드는 성질. 공간 지역성, 시간 지역성은 경험적 성질로, 캐시는 이러한 성질을 이용해 설계됨.
    - 공간 지역성
        - 한 번 접근한 주소 주변의 데이터도 곧 접근할 가능성이 높다는 성질
        - 캐시는 캐시라인 단위로 가져오게 설계됨
    - 시간 지역성
        - 최근에 접근한 데이터를 가까운 미래에 다시 접근할 가능성이 높다는 성질
        - 캐시가 꽉 찼을 때, 오랫동안 안 쓴 데이터를 버림

* prefetch
    - CPU가 사용할 데이터를 예측해 미리 캐시로 가져오는 동작
    - 패턴을 분석해 수행됨(연속된 주소, 일정한 간격 등)

* 배열
    - 원소가 연속적으로 배치됨 -> 한 캐시라인에 여러 원소가 함께 들어옴 -> 다음 원소 접근이 캐시 히트 되기 쉬움 + 하드웨어 prefetch 잘 동작
* 연결 리스트
    - 노드가 흩어져 있고, 다음 노드는 포인터로 따라감 -> 포인터 추적 때문에 다음 주소 예측/prefetch하기 어려움 -> 캐시 미스 증가
    - 노드마다 포인터를 저장하는 오버헤드 존재: 동일 데이터 대비 메모리 사용량 증가

[정리]
* CPU 캐시가 캐시라인 단위로 가져오고, 원소가 연속 배치된 배열이 유리
* 연속 순회 시 prefetch 용이

---

## Q6. 연결 리스트와 배열 중 어떤 상황에서 무엇을 선택해야 하는가?

[답변]
배열: 요소의 변경이 적은 경우, 요소에 대한 조회가 잦은 경우
연결 리스트: 요소의 변경이 많고, 조회가 잦지 않은 경우

[보완]
* 배열
    - 인덱스 기반 랜덤 접근
    - 순차 순회 잦음 + 성능 중요
    - 원소 수 예측 가능
* 연결 리스트
    - 중간 삽입/삭제 매우 빈번
    - 삽입/삭제 위치 노드 이미 가리키고 있는 경우(위치 모르면 조회 필요: 이점 사라짐)
    - 노드 연결만 바꾸는 작업이 중요

[정리]
* 대부분 배열: 빠른 접근/순회, 구현 단순, 캐시 효율
* 연결 리스트는 특수 상황: 삽입/삭제 위치 알고, 중간 수정 잦음

---

## 📎 참고 자료
<!-- 공부하면서 참고한 링크를 여기에 추가해주세요 -->

---

## 💬 토론 포인트
<!-- PR 리뷰 또는 스터디 중 나온 추가 질문이나 논의 사항을 기록해주세요 -->
