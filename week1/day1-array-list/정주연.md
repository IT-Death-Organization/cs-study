# Day1-배열과 리스트

> 📅 2025.02.13 | 📁 Week 1
> 

---

## 🧠 학습 질문

- [x]  배열의 접근이 O(1)인 이유를 메모리 주소 계산 관점에서 설명하면?
- [x]  배열의 중간 삽입/삭제가 O(n)인 이유는?
- [x]  동적 배열이 크기가 가득 찼을 때 2배로 확장하는 이유는?
- [x]  재할당 시 기존 요소들을 복사하는데 왜 amortized O(1)이 되는가?
- [x]  Cache locality 관점에서 배열이 연결 리스트보다 유리한 이유는?
- [x]  연결 리스트와 배열 중 어떤 상황에서 무엇을 선택해야 하는가?

## 1. 배열의 접근이 O(1)인 이유를 메모리 주소 계산 관점에서 설명

### 알아야 할 핵심 원리

배열의 어느 위치에 있는 데이터든 인덱스 번호만 알면 동일한 시간 내에 접근할 수 있음

→ 이것이 가능한 이유 : 배열은 메모리상에서 연속적인 공간(Contiguous Memory Location)을 차지하며, 동일한 크기의 데이터 타입으로 구성되기 때문

### 컴퓨터가 특정 인덱스의 주소를 찾는 과정

찾고자 하는 주소 = 시작 주소(Base Address) + (인덱스 × 데이터 타입의 크기)

- 예시
    
    4바이트 크기의 정수(int)를 담는 배열이 메모리 주소 **1000번**에서 시작한다고 가정
    
    인덱스 0 → 1000+(0x4) = 1000
    
    인덱스 1 → 1000+(1x4) = 1004 
    
    인덱스 100 → 1000+(100x4) = 1400
    
    0번을 찾든, 100번을 찾든 컴퓨터의 작업의 양은 동일함 (곱셈 1 덧셈 1) 
    

어느 인덱스 값이든 딱 한 번의 산술 연산으로 끝난다.

즉, 입력값 크기와 무관하게 일정한 시간이 소요된다 ⇒ 따라서 시간 복잡도는 O(1) 

### 전제조건

- 연속적 메모리 배치
    
    데이터가 메모리 곳곳에 흩어져 있다면 인덱스만으로 위치를 계산할 수 없음 → 배열은 선언 시점에 연속된 빈 공간을 할당받아야 한다. 
    
- 동일 데이터 타입
    
    만약 배열의 각 요소가 크기가 다르다면(e.g. 0번은 4바이트, 1번은 8바이트), 단순히 인덱스 * 크기 공식을 적용할 수 없고 앞의 요소들을 모두 확인해야 하므로 O(n)이 될 것이다. 
    

## 2. 배열의 중간 삽입/삭제가 O(n)인 이유

### 핵심 원리

배열은 메모리 상에서 빈틈없이 연속성을 띤다. O(1)의 빠른 접근이 보장되려면, 이 연속성이 깨지면 안 된다. 중간에 데이터를 삽입/삭제 하면 그 자리를 메꾸거나 만들어야 한다.(데이터 이동; Shifting) ⇒ 이것이 O(n)의 원인(배열의 크기 n에 비례하기 때문) 

### 시간 복잡도 계산

Best Case: 배열의 맨 뒤에 삽입/삭제하는 경우. 아무도 이동할 필요가 없으므로 O(1)

Worst Case: 배열의 맨 앞에 삽입/삭제하는 경우. 모든 요소($n$개)를 이동시켜야 하므로  O(n)

Average Case: 보통 중간 어딘가에 작업하므로 약 n/2개를 이동시킵니다. Big-O 표기법에서는 상수를 제외하므로 이 역시 O(n)

+ Java의 `System.arraycopy()` 등에서는 요소를 하나하나 반복문으로 옮기지 않고, 메모리 블록 전체를 통째로 복사하는 방식을 사용하여 최적화한다. 하지만 이 역시 물리적으로는 데이터를 이동시키는 행위이므로, 이론적인 시간 복잡도는 여전히 O(n)

## 3. 동적 배열이 크기가 가득 찼을 때 2배로 확장하는 이유

e.g. Java의 `ArrayList`, C++의 `std::vector`

### 핵심 원리

동적 배열은 기본적으로 크기가 고정된 배열이다. 데이터가 꽉 차면 더 큰 배열을 새로 만들고 기존 데이터를 복사한다. → 이 복사 과정이 O(n)

- 만약, 데이터 넣을 때마다 크기를 1씩 늘린다면? → 매번 O(n)의 복사 작업 → 성능 저하
- 2배씩 늘린다면? → O(n) 연산이 가끔씩 발생 → 이 비용을 저렴한 연산들이 나눠 가짐 → 평균 O(1)

### 왜 하필 2배?

실제 구현체마다 배율은 조금씩 다름 (Java `ArrayList`는 1.5배, C++ `std::vector`는 2배 등)

- 2배 미만의 경우
2배로 하면 이전 단계 메모리 공간들의 합보다 새로 할당받는 공간이 더 큼 → 이전에 쓴 메모리 주소 재사용 어려움 → 2배 미만으로 사용하여 메모리 효율성 높임
- 크게 늘리지 않는 경우 
10, 100배씩 늘리면 메모리 낭비가 심해짐 → 시간복잡도(O(1))를 보장하면서도 메모리 낭비를 최소화하는 지점 : 보통 1.5배~2배 사이

## 4. 재할당 시 기존 요소들을 복사하는데 왜 amortized O(1)인가?

동적 배열(ArrayList, vector 같은 거)은 꽉 차면 더 큰 배열을 새로 만들고, 기존 원소를 전부 복사해 옮기기에,이 순간만 보면 한 번에 O(n) 

근데 핵심은 매 삽입마다 O(n)이 터지는 게 아니라, 가끔씩만 O(n)이 터짐

보통 용량을 2배로 증가시키는 전략을 쓰는데, 이러면 리사이즈가 발생하는 시점이 지수적으로 멀어짐

- 예시 
용량이 1 → 2 → 4 → 8 → 16… 이렇게 늘어난다고 할 때,
    - 용량 1에서 2로 갈 때 복사 1개
    - 2에서 4로 갈 때 복사 2개
    - 1 + 2 + 4 + … + (n/2) = n - 1 = O(n)
    - 즉, n번 push(append) 하는 동안 “전체 복사 비용”이 O(n)이니까,
    
    한 번 삽입당 평균 비용은:O(n) / n = O(1)
    

이것이 amortized O(1) 의 의미임. 

즉, 리사이즈는 비싸지만(한 번 O(n)), 그 비싼 일이 자주 일어나지 않게 설계되어서 전체 평균이 O(1) 이 됨.

## 5. Cache locality 관점에서 배열이 연결 리스트보다 유리한 이유는?

CPU는 메모리에서 데이터를 가져올 때 한 칸만 X. 

보통 캐시라인 단위로 주변 데이터까지 묶어서 가져옴. → 다음에 쓸 데이터가 근처에 있으면 빠르게 처리됨. (spatial locality) 

- 배열 (유리)
    - 공간 지역성(Spatial Locality): 데이터가 메모리상에 연속적으로 붙어 있음
    - 캐시 라인(Cache Line): CPU는 메모리를 읽을 때 필요한 데이터뿐만 아니라 주변 데이터(보통 64바이트)를 한 번에 캐시로 가져옴.
    - 효과: `arr[0]`을 읽으면 뒤에 있는 `arr[1]`, `arr[2]` 등도 이미 캐시에 들어와 있어 접근 속도가 매우 빠름 (캐시 히트).
- 연결 리스트 (불리)
    - 메모리 파편화: 노드들이 메모리 여기저기에 흩어져 있음.
    - 효과: 다음 노드로 갈 때마다 캐시에 없는 새로운 주소를 찾아 느린 RAM에 다시 접근해야 함 (캐시 미스)

### 배열이 유리한 이유 (연속 메모리)

배열은 원소가 연속된 주소에 붙어 있어.

- `a[i]`를 읽으면, 캐시 라인에 `a[i+1], a[i+2]...` 같은 다음 원소들도 같이 딸려옴
- 그래서 순회(for문)할 때 캐시 히트가 계속 나서 빠름
- 분기 예측도 단순하고, 프리페치(prefetch)도 잘 먹힘

### 연결 리스트가 불리한 이유 (흩어진 메모리 + 포인터 추적)

연결 리스트는 각 노드가 보통 힙 여기저기에 흩어져 있어.

- 현재 노드의 `next` 포인터를 따라가야 다음 주소를 알 수 있음 (pointer chasing)
- 다음 노드가 어디 있을지 예측이 어려워서 캐시에 미리 올리기 힘듦
- 결과적으로 순회 중 캐시 미스가 자주 나고, 메모리 대기 시간이 커짐
- 게다가 노드마다 `next` 포인터 같은 오버헤드도 있어(메모리 더 먹고 캐시 효율 더 나빠짐)

## 6. 연결 리스트와 배열 중 어떤 상황에서 무엇을 선택해야 하는가

1. 배열(Array / ArrayList)을 선택하는 경우
데이터의 조회가 빈번하고, 데이터의 크기가 어느 정도 예측될 때 

- 임의 접근(Random Access) 필요: 인덱스를 통해 특정 요소에 즉시 접근($O(1)$)해야 할 때.
- 순차적 조회(Iteration) 중심: 캐시 지역성 덕분에 메모리를 순차적으로 읽는 작업에서 연결 리스트보다 압도적으로 빠름.
- 메모리 효율: 데이터 외에 추가적인 포인터 공간이 필요 없으므로, 데이터 크기가 작을수록 메모리 낭비가 적음.
- 데이터 추가/삭제가 주로 맨 뒤에서 발생: 동적 배열의 끝에 데이터를 추가하는 것은 분할 상환 O(1)이므로 효율적임.

2. 연결 리스트(Linked List)를 선택하는 경우
데이터의 삽입과 삭제가 빈번하고, 데이터의 총 개수를 예측하기 어려울 때 유리합니다.

- 중간 삽입/삭제가 빈번: 삽입/삭제할 위치의 포인터를 알고 있다면, 데이터 이동 없이 포인터만 변경(O(1))하면 됨.
- 크기 변화가 극심함: 배열처럼 재할당(Resizing) 과정이 없으므로, 데이터가 수시로 추가되고 삭제되는 환경에서 메모리 관리가 유연함.
- 대용량 데이터의 잦은 병합: 두 리스트를 하나로 합칠 때 포인터만 연결하면 되므로 O(1)로 처리가 가능함.

---

## 📎 참고 자료

[<!--](https://cheonjoosung.github.io/blog/cs-arraylinked) 공부하면서 참고한 링크를 여기에 추가해주세요 [-->](https://cheonjoosung.github.io/blog/cs-arraylinked)

[https://cheonjoosung.github.io/blog/cs-arraylinked](https://cheonjoosung.github.io/blog/cs-arraylinked)

[https://securityhacker.tistory.com/entry/자료구조-배열-vs-연결-리스트](https://securityhacker.tistory.com/entry/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EB%B0%B0%EC%97%B4-vs-%EC%97%B0%EA%B2%B0-%EB%A6%AC%EC%8A%A4%ED%8A%B8)

---

## 💬 토론 포인트

<!-- PR 리뷰 또는 스터디 중 나온 추가 질문이나 논의 사항을 기록해주세요 -->