# Day 1: 배열(Array)과 리스트(List)
> 📅 2025.02.13 | 📁 Week 1

---

## 🧠 학습 질문

- [ ] 배열의 접근이 O(1)인 이유를 메모리 주소 계산 관점에서 설명하면?
- [ ] 배열의 중간 삽입/삭제가 O(n)인 이유는?
- [ ] 동적 배열이 크기가 가득 찼을 때 2배로 확장하는 이유는?
- [ ] 재할당 시 기존 요소들을 복사하는데 왜 amortized O(1)이 되는가?
- [ ] Cache locality 관점에서 배열이 연결 리스트보다 유리한 이유는?
- [ ] 연결 리스트와 배열 중 어떤 상황에서 무엇을 선택해야 하는가?

---

## Q1. 배열의 접근이 O(1)인 이유를 메모리 주소 계산 관점에서 설명하면?
배열은 선형 구조로 연속된 주소에 데이터 값들이 저장된다. 배열의 주소값은 인덱스 0번의 주소값이며, 인덱스가 i인 주소값은 다음과 같다.
i번째 인덱스 주소 = 인덱스 0의 주소 + (i * 요소의 크기)

요소의 크기는 데이터 타입마다 다르다. 예를 들어, int는 4바이트이다.

예를 들어, 시작 주소가 100이고 int 배열이라면,
arr[3]의 주소 = 100 + (3 * 4) = 112 로 계산된다.

이렇게 i번째 인덱스 주소를 접근하는 방법은 덧셈과 곱셉으로 이루어진 산술 연산이다. 산술연산은 O(1)로 수행된다. 
산술연산이 O(1)로 간주되는 이유는 생각보다 간단하다. CPU 내에서 정해진 비트 수(예: 32비트 또는 64비트) 내에 동작하는 ALU를 사용하여 한 번의 클럭 사이클 내에 연산을 완료하기 때문이다. 이로인해 데이터 크기가 커져도 연산 시간은 항상 고정된다.

---

## Q2. 배열의 중간 삽입/삭제가 O(n)인 이유는?
배열은 앞서 언급했듯, 인덱스의 주소들이 모두 연속되어야 한다. 즉, 배열의 중간에 데이터를 삽입하거나 삭제를 한 경우 빈 곳이 생기지 않도록 데이터를 움직여줘야 한다.  
데이터를 중간에 삽인한 경우, 삽입된 위치부터 뒤에 있는 데이터들은 자리를 양보하여 뒤로 밀려난다. 반대로 데이터를 삭제한 경우, 위에 있는 데이터들을 앞으로 당겨와야 한다.

시간 복잡도는 최악의 경우를 계산하므로, 데이터를 0번째 인덱스에 삽입하거나 삭제한 경우, 뒤에 있는 n-1개의 데이터들을 움직여줘야하기에 O(n)이다.

---

## Q3. 동적 배열이 크기가 가득 찼을 때 2배로 확장하는 이유는?
동적 배열이란 크기가 고정되지 않은 배열을 의미한다. 만약 기존 크기에 데이터가 전부 찬 경우, 배열의 크기를 resize 한다. 이 과정은 다음과 같다:
1. 더 큰 새 메모리 블록을 할당
2. 기존 원소들을 전부 새 공간으로 복사
3. 기존 메모리 해제

여기에서 2번인 원소 복사는 원소 N개를 복사해야하기 때문에 결구 resize의 시간복잡도는 O(N)이 된다.

배열이 꽉 찰 때마다, 크기를 1칸씩만 늘린다면, O(N)의 작업을 자주, 여러번 하게 된다. 
예를 들어, 배열의 크기는 1 -> 2 -> 3 -> 4이다.
하지만, resize의 횟수를 줄이기 위해 크기를 기존 크기의 2배로 늘리게 한다면, resize가 아주 가끔만 발생하게 된다. 이 경우에는 크기가 1 -> 2 -> 4 -> 8 -> 16 -> ..으로 늘어난다. 이 경우, 복사 횟수는 1 + 2 + 4 + 8 + ..로 등비수열이 된다. N번 배열의 끝에 데이터를 삽입(append)하는 동안, 전체 복사 비용이 O(N)이 되고 평균적으로 O(1)이다.

그렇다면 왜 하필 2배일까?
2배씩 늘리는 전략은 resize 횟수가 적고, 메모리 낭비도 과하지 않으며, 평균적으로 O(1)을 보장하기 때문에 가장 균형이 좋다.

---

## Q4. 재할당 시 기존 요소들을 복사하는데 왜 amortized O(1)이 되는가?
이 문제는 위 3번의 복사 비용 내용을 더욱 구체적으로 설명한다.

Amortized란, 개별 연산은 비쌀 수 있지만 여러번의 연산을 평균적으로 나누어 계산했을 때의 시간 복잡도를 의미한다. 

동적 배열에서 resize가 발생하면 O(N)의 복사가 일어난다고 위 3번 문제에서 확인하였다. 하지만 resize는 매법 발생하지 않는다. 용량이 가득 찬 경우에만 발생하고, 용량은 2배씩 증가한다.

위 3번에서 언급한대로 복사 비용은 1 + 2 + 4 + 8 + .. + N이되며, 등비수열의 합은 최대 2N-1로, 전체 비용은 결국 O(N)이 된다. 즉, N번의 append 동안 전체 비용이 O(N)이므로,

평균 비용 = O(N) / N = O(1) 이 된다.

따라서, append의 시간 복잡도는 amortized O(1)이 된다.

---

## Q5. Cache locality 관점에서 배열이 연결 리스트보다 유리한 이유는?
캐시는 RAM보다 훨씬 빠르기 때문에 CPU는 매번 RAM을 읽는게 아닌, 캐시를 먼저 확인한다.

Cache locality란, CPU가 메모리를 효율적으로 사용하기 위해 가까운 위치의 데이터를 함계 활용하는 특성이다. 프로그램은 보통 Temporal Locality와 Spatial Locality를 포함한다. 이 중에서 Spatial Locality(공간 지역성)은 어떤 데이터를 접근하면 그 주변 데이터도 곧 접근할 가능성이 극대화됨을 나타낸다.

위 내용을 바탕으로 배열과 연결 리스트에 적용해보자.

배열은 연속된 메모리를 사용한다. 메모리상 데이터들이 붙어있기 때문에 배열의 한 원소를 읽으면, 옆에 있는 여러 원소도 같이 캐시에 올라온다. 즉, 배열은 공간 지역성을 아주 잘 활용하기에 매우 빠르게 데이터를 접근할 수 있다.

반면, 연결 리스트는 메모리상에 흩어져 있다. 각 노드는 따로 할당되고, 다음 노드가 어디에 있는지 포인터를 따라가야한다. 이 때문에 공간 지역성이 거의 없다는 단점을 가지고 있다. 

이론적인 배열과 연결 리스트의 접근 성능은 O(N)으로 같다. 하지만, 배열은 캐시 효율을 극대화하는 자료구조이기 때문에 실제 실행 속도는 배열이 훨씬 빠르다. 

---

## Q6. 연결 리스트와 배열 중 어떤 상황에서 무엇을 선택해야 하는가?
배열:
- 접근이 잦고,
- 삽입과 삭제가 적은 경우
배열은 연속된 메모리를 사용하기 때문에 랜덤 접근이 O(1)이며, 캐시 효율이 높아 실제 성능이 우수하다.

연결 리스트:
- 접근이 적고,
- 삽입과 삭제가 잦은 경우
- 혹은 삽입과 삭제 위치를 이미 알고 있는 경우
연결 리스트는 특정 노드 위치를 알고 있다면 삽입/삭제가 O(1)이다. 반면 배열은 요소를 이동시켜야 하므로 O(N)의 비용이 발생한다.

---

## 📎 참고 자료
<!-- 공부하면서 참고한 링크를 여기에 추가해주세요 -->
https://noahlogs.tistory.com/29
https://moonlight-spot.tistory.com/entry/%EB%B0%B0%EC%97%B4Array-vs-%EC%97%B0%EA%B2%B0%EB%A6%AC%EC%8A%A4%ED%8A%B8Linked-List-%EC%B0%A8%EC%9D%B4%EC%A0%90-%EB%B9%84%EA%B5%90-%EB%B0%8F-%EC%82%AC%EC%9A%A9-%EC%9D%B4%EC%9C%A0

---

## 💬 토론 포인트
<!-- PR 리뷰 또는 스터디 중 나온 추가 질문이나 논의 사항을 기록해주세요 -->
