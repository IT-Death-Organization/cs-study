# Day 1: 배열(Array)과 리스트(List)

> 📅 2025.02.13 | 📁 Week 1

---

## 🧠 학습 질문

- [x] 배열의 접근이 O(1)인 이유를 메모리 주소 계산 관점에서 설명하면?
- [x] 배열의 중간 삽입/삭제가 O(n)인 이유는?
- [x] 동적 배열이 크기가 가득 찼을 때 2배로 확장하는 이유는?
- [x] 재할당 시 기존 요소들을 복사하는데 왜 amortized O(1)이 되는가?
- [x] Cache locality 관점에서 배열이 연결 리스트보다 유리한 이유는?
- [x] 연결 리스트와 배열 중 어떤 상황에서 무엇을 선택해야 하는가?

---

### 📌 [Q1] 배열의 접근이 O(1)인 이유를 메모리 주소 계산 관점에서 설명하면?

접근은 배열 내에서 n번째 인덱스에 해당하는 값을 찾아내는 연산이다.
이때, 배열의 접근이 O(1)의 시간복잡도를 가지는 이유는 무작위 접근(Random Access)이 가능하기 때문이다. 이를 설명하는 핵심 원리는 아래와 같다.

1. 연속된 메모리 할당 (Contiguous Memory Allocation)
   **배열은 생성될 때 메모리 상에서 빈틈없이 연속된 공간을 점유**하기 때문에 각 요소의 위치를 수학적으로 예측할 수 있다.

2. 메모리 주소 계산 공식 (Offset Calculation)
   CPU가 배열의 특정 인덱스(i)에 접근할 때, 실제 메모리 주소를 찾아내는 과정은 아래와 같은 단순한 산술 연산이다. (한 번의 연산으로 결과가 나온다.)

**Address(i) = Base Address + (i x Size of Element)**

위에서 알 수 있듯, 인덱스가 0이든 10000이든 상관없이 우리는 덧셈 & 곱셈 연산만 수행하면 즉시 주소를 알 수 있다. 데이터 개수(n)가 늘어난다고 해도 이 계산 과정은 복잡해지지 않는다. 따라서 **배열의 요소에 접근할 때 시간복잡도는 배열의 크기와는 상관없이 항상 상수 시간인 O(1)** 이다.

### 📌 [Q2] 배열의 중간 삽입/삭제가 O(n)인 이유는?

배열에서 중간에 데이터를 삽입, 삭제할 때의 시간복잡도가 O(N)인 이유는 **데이터의 연속성(Cotiguousness)을 유지하기 위한 물리적인 이동**이 필요하기 때문이다.
**배열은 메모리 상에서 항상 연속**해야 하므로, 중간에 변화가 생기면 이에 맞춰 나머지 원소들도 조정을 해야 한다.

1. 원소 삽입
   - 만약 2번 인덱스에 새로운 값을 넣으려고 한다면 2번 인덱스 뒤에 있는 모든 요소(3번부터 마지막까지)를 한 칸씩 뒤로 밀어내야 한다.(Shifting)
   - 최악의 경우: 맨 앞(0번 인덱스)에 데이터를 삽입 -> **n개의 기존 데이터를 모두 한 칸씩 뒤로 밀어야 하므로, n번의 연산이 발생해 O(N)이 된다.**

2. 원소 삭제
   - 배열은 중간이 비어있으면 O(1) 접근 공식을 사용할 수 없다. 따라서 삭제된 인덱스 뒤에 있는 모든 요소를 한 칸식 앞으로 당겨야 한다.(Shifting)
   - 최악의 경우: 맨 앞(0번 인덱스) 데이터를 삭제 -> **나머지 n-1개의 데이터를 모두 앞으로 이동시켜야 하므로 O(N)이 된다.**

### 📌 [Q3] 동적 배열이 크기가 가득 찼을 때 2배로 확장하는 이유는?

<details>
<summary>동적 배열(Dynamic Array)이란?</summary>
<div markdown="1">
• 실행 중에(runtime) 크기가 자유롭게 변할 수 있는 배열 <br />
• 일반적인 배열(Static Array)는 처음에 배열의 크기가 지정되지만, 동적 배열은 데이터가 들어오는 양에 따라 스스로 크기를 조정한다. <br />
• 동적 배열은 내부적으로는 정적 배열을 사용하지만, 확장이 필요할 땐 내부적으로 배열을 새로 만들거나 복사하면서 알아서 크기를 맞춰주는 자료구조이다.
</div>
</details>
<br />

<details>
<summary>복사란?</summary>
<div markdown="1">
• 기존 배열의 모든 원소를 더 큰 새 배열로 하나씩 옮기는 것
</div>
</details>
<br />

<details>
<summary>배열이 꽉 찼다는 것은? & 복사 비용이 생기는 이유</summary>
<div markdown="1">
• 배열은 메모리 상에서 연속된 상태로 존재한다. 만약 용량이 4인데 4개가 꽉 찬 상태에서 원소를 추가하고 싶을 때, 바로 뒤에 원소를 붙일 수 없다. (바로 옆 주소가 비어있다는 보장이 없기 때문!)

따라서 <br />
• 더 큰 배열을 새로 만든다. (ex. 크기가 4x2=8인 배열)<br />
• 기존 배열의 모든 값을 새 배열로 옮긴다. (복사)<br />
• 그 다음 새 원소를 추가한다.

<기존 배열>
[10][20][30][40]

<새 배열>
[ ][ ][ ][ ][ ][ ][ ][ ]

<복사 후>
[10][20][30][40][ ][ ][ ][ ]

만약 기존 배열에 1000개가 들어있다면? <br />
• 새 배열을 만든 후 1000개를 하나하나 옮겨야 한다. <br />
• 따라서 확장할 때 O(N)의 비용이 드는 것이다.

</div>
</details>
<br />

동적 배열은 내부적으로 고정된 크기의 배열을 할당받아 사용한다. 데이터가 가득 차면 더 큰 새로운 배열을 할당하고, 기존 배열을 복사하는 재할당(resizing) 과정을 거친다.

동적 배열이 가득 찼을 때 배열을 2배로 확장하는 이유는 **확장 횟수를 줄여 전체 삽입 연산의 평균 시간 복잡도를 O(1)로 유지하기 위해서**이다.

1. 만약 배열이 가득 찰 때마다 1칸씩 늘리면?
   - 매번 새로운 배열을 만들고 기존 배열을 전부 복사해야 한다.
   - 이렇게 되면 n개의 원소를 추가할 때, 복사가 계속 발생해서 O(n²)에 가까워져 성능이 매우 저하된다.

<details>
<summary>O(n²))인 이유</summary>
<div markdown="1">
• 처음 용량이 1이라고 가정, 원소를 n개 넣는다고 하면 배열이 꽉 찰 때마다 계속 새 배열을 만들고 기존 원소를 전부 복사해야 한다. <br />

ex) 5개를 더 넣으면 <br />
1번째 추가 → 복사 1개<br />
2번째 추가 → 복사 2개<br />
3번째 추가 → 복사 3개<br />
4번째 추가 → 복사 4개<br />
5번째 추가 → 복사 5개<br />
총 복사 횟수: 1 + 2 + 3 + 4 + 5<br />

-> n개를 넣으면 복사 횟수는 1 + 2 + 3 + ... + n 이므로 이를 수학적으로 표현하면 n(n+1)/2<br />
-> 이를 빅오표기법으로 표현하면 O(n²)

</div>
</details>
<br />

2. 2배로 확장하면 (1 → 2 → 4 → 8 → 16 → 32 →...)
   - 복사는 가끔만 발생한다.
   - 대부분의 push 연산은 단순히 뒤에 추가만 한다.
   - 2배 증가는 등비수열이기 때문에, 복사 횟수의 총합이 대략 2N정도이다.
   - n개의 데이터를 추가하는 동안 발생하는 전체 복사 비용은 O(n)이고, 각 삽입 연산의 평균 시간 복잡도는 O(1)이 된다. => 이를 **분할 상환 분석**이라고 한다.

### 📌 [Q4] 재할당 시 기존 요소들을 복사하는데 왜 amortized O(1)이 되는가?

**\*amortized(분할 상환)** <br />
: 비용, 시간, 혹은 자원 사용량을 일시불이나 최악의 경우로 계산하지 않고, 일련의 연산이나 기간에 걸쳐 평균적으로 균등하게 분배하여 계산하는 방식

재할당 시 발생하는 O(n)의 비용은 매번 발생하는 것이 아니라 아주 가끔 발생한다. 이 비용을 이후에 들어올 수많은 O(1) 연산들이 나누어 부담하기 때문에, 전체적인 관점에서의 평균 비용은 상수가 된다.

즉, 재할당 시 복사 비용은 O(n)이지만, 용량을 2배로 확장하면 확장 횟수가 로그 수준으로 줄어들어 n번 삽입 동안 총 복사 비용이 O(n)이다. 따라서 각 삽입 연산의 평균 시간 복잡도는 Amortized O(1)이 된다.

### 📌 [Q5] Cache locality 관점에서 배열이 연결 리스트보다 유리한 이유는?

<details>
<summary>Cache locality(Spatial Locality)란?</summary>
<div markdown="1">
• CPU는 RAM에서 바로 데이터를 계속 읽지 않는다. <br />
• 대신 RAM에서 데이터를 가져옴 -> 캐시라는 작은 고속 메모리에 저장 -> 이때 그 근처 데이터도 같이 가져옴 <br />
• 이를 공간 지역성(Cache locality, Spatial Locality)이라고 한다. <br />
• "한 번 접근한 데이터 근처를 또 접근할 가능성이 높다."
</div>
</details>
<br />

배열은 메모리 상에서 연속된 공간에 저장되기 때문에, CPU가 한 번 데이터를 읽을 때 인접한 데이터도 함께 캐시에 적재해 효율적으로 활용할 수 있다. (캐시 히트율 높음) 반면 연결 리스트는 메모리 상 연속되지 않고, 노드가 메모리 여기저기에 흩어져 있어 캐시 미스가 자주 발생해 실행 속도가 느리다.

이론상으로 배열 탐색과 연결 리스트 탐색은 똑같이 O(N)의 시간 복잡도를 같지만, 위와 같은 이유로 실제 실행 속도는 배열이 훨씬 빠른데 이 이유가 바로 **Cache locality**이다.

### 📌 [Q6] 연결 리스트와 배열 중 어떤 상황에서 무엇을 선택해야 하는가?

**읽기/랜덤 접근이 많으면 배열을, 중간 삽입/삭제가 많으면 연결 리스트를 선택**해야 한다.

1. 배열을 선택해야 하는 경우
   • 인덱스로 빠르게 접근해야 할 때 -> O(1) (연결 리스트는 O(N)) <br />
   • 순차 접근이 많을 때 (Cache locality) <br />
   • 메모리 오버헤드를 줄이고 싶을 때 (연결 리스트는 값+포인터를 저장해야 하므로 메모리가 더 많이 필요함)<br />

2. 연결 리스트를 선택해야 하는 경우<br />
   • 중간 삽입/삭제가 빈번할 때 -> 포인터만 바꾸면 되므로 O(1) (배열은 원소를 모두 밀어야 하므로 O(N))<br />
   • 크기를 예측하기 어려울 때 (배열은 확장 시 복사 비용이 발생하지만, 연결 리스트는 노드 단위로 늘어나므로 큰 재할당이 필요없다.)<br />

\* 이론적으로는 연결 리스트가 삽입 시 O(1)이지만, 실제로는 (메모리에 흩어져 있음/캐시 미스 확률이 높음/포인터 오버헤드)와 같은 이유 때문에 배열이 더 빠른 경우가 많다. 따라서 현대 언어 라이브러리는 대부분 배열 기반이다.

---

## 📎 참고 자료

<!-- 공부하면서 참고한 링크를 여기에 추가해주세요 -->

---

## 💬 토론 포인트

<!-- PR 리뷰 또는 스터디 중 나온 추가 질문이나 논의 사항을 기록해주세요 -->
