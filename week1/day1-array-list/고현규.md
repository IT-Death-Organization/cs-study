# Day 1: 배열(Array)과 리스트(List)
> 📅 2025.02.13 | 📁 Week 1

---

## 🧠 학습 질문

- [x] 배열의 접근이 O(1)인 이유를 메모리 주소 계산 관점에서 설명하면?
- [x] 배열의 중간 삽입/삭제가 O(n)인 이유는?
- [x] 동적 배열이 크기가 가득 찼을 때 2배로 확장하는 이유는?
- [x] 재할당 시 기존 요소들을 복사하는데 왜 amortized O(1)이 되는가?
- [x] Cache locality 관점에서 배열이 연결 리스트보다 유리한 이유는?
- [x] 연결 리스트와 배열 중 어떤 상황에서 무엇을 선택해야 하는가?

<br>

# 1. 배열의 접근이 `O(1)`인 이유 (메모리 주소 계산 관점)

배열을 메모리 공간에 저장할 때는 **연속된 메모리 공간**에 저장합니다.

예를 들어 정수(int)형 배열이 메모리의 1000번지부터 시작한다고 가정해봅시다.

정수의 크기는 4바이트이므로, 각 요소들은 4바이트의 간격을 두고 다닥다닥 붙어 있게 됩니다.

- 0번 요소: 1000번지
- 1번 요소: 1004번지
- 2번 요소: 1008번지
- 3번 요소: 1012번지
- 4번 요소: 1016번지


여기서 특정 인덱스의 값을 알고 싶은 경우 앞에서부터 하나씩 세면서 찾아가는 것이 아닌,계산 공식을 사용합니다.

$$\text{Target Address} = \text{Base Address} + (\text{Index} \times \text{Element Size})$$

* Base Address (시작 주소): 배열이 시작되는 첫 번째 요소의 메모리 주소입니다. (예시의 경우 1000)
* Index (인덱스): 찾고자 하는 요소의 위치 번호입니다.
* Element Size (요소 크기): 자료형의 크기(예: int는 4바이트, double은 8바이트 등)입니다.

데이터 양이 얼마나 있든 상관없이 주소 계산 한번이면 원하는 데이터의 위치를 바로 찾을 수 있게 됩니다.

참고로 컴파일러는 프로그래밍 언어의 명세(Specification)에 따라 각 타입의 크기를 이미 알고 있습니다.

<br>

# 2. 배열의 중간 삽입/삭제가 `O(n)`인 이유는?

배열은 **연속된 메모리 공간**에 저장되기 때문에, 중간에 데이터를 삽입하거나 삭제하려면 **뒤따라오는 모든 요소들을 한 칸씩 밀어주는 작업**이 필요합니다.

예를 들어, 5개의 요소를 가진 배열에서 2번 인덱스(세 번째 칸)에 새로운 요소를 삽입한다고 가정해봅시다.

**[삽입 전]**
```
[10, 20, 30, 40, 50]
```

**[삽입 후]**
```
[10, 20, 99, 30, 40, 50]
```

이 과정에서 30, 40, 50은 뒤로 한 칸씩 밀려나야 합니다. 만약 배열의 크기가 100개라면, 2번 인덱스 뒤의 98개 요소를 모두 이동시켜야 합니다. 이처럼 이동해야 하는 요소의 개수가 데이터의 양(n)에 비례하기 때문에 시간 복잡도는 `O(n)`이 됩니다.

삭제의 경우도 마찬가지입니다. 2번 인덱스의 요소를 삭제하면 뒤따라오는 요소들을 앞으로 당겨와야 빈 공간을 메울 수 있습니다.

참고로, 삽입/삭제가 빈번하게 필요한 경우에는 배열보다 LinkedList가 더 좋은 선택일 수 있습니다.

<br>

# 3. 동적 배열이 크기가 가득 찼을 때 2배로 확장하는 이유는?

동적 배열(Dynamic Array, Java의 ArrayList나 Python의 List 등)이 가득 찼을 때 크기를 2배로 확장하는 이유는 **삽입/삭제 연산의 효율성을 유지하기 위해서**입니다.

정확히 말하자면 언어별 설계 철학에 따라 1.5배, 2배 등 다양한 비율로 확장할 수 있습니다.

배열에 요소들이 늘어날 경우 더 많은 메모리 공간이 필요한 것은 사실입니다. 이때 배수가 너무 크면(예: 10배) 메모리 낭비가 심해지고, 너무 작으면(예: 1.1배) 확장이 너무 잦아져 성능이 저하될 수 있습니다. 2배로 확장하는 것은 이 두 가지 문제를 적절히 해결할 수 있는 균형 잡힌 선택입니다.

<br>

# 4. 재할당 시 기존 요소들을 복사하는데 왜 amortized `O(1)`이 되는가?

확장/복사의 비용은 `O(n)`으로 비쌉니다. 하지만 처음에는 자주 확장하는 것 같지만, 배열이 커질 수록 확장이 일어나는 빈도가 기하급수적으로 줄어들고 삽입(`O(1)`)이 일어나는 빈도가 훨씬 많아지기 때문에 전체적으로 보면 평균적으로 `O(1)`의 비용이 든다고 볼 수 있습니다.

이 과정을 수학적으로 계산해 보면, n개의 요소를 삽입하는 동안 발생하는 총 복사 비용은 대략 2n에 수렴합니다. (1+2+4+8... 식으로 늘어나는 등비급수의 합 원리)
결국 전체 비용(2n)을 삽입 횟수(n)로 나누면, 요소 하나당 평균 비용은 약 2가 됩니다. 2는 데이터 양(n)과 상관없는 상수이므로, `O(1)`이 됩니다. 이를 분할 상환(Amortized)이라고 부릅니다.

<br>

# 5. Cache locality 관점에서 배열이 연결 리스트보다 유리한 이유는?

CPU는 데이터를 처리하기 위해 메인 메모리(RAM)에서 값을 가져오지만, 이 과정은 CPU의 처리 속도에 비해 매우 느립니다. 이를 보완하기 위해 훨씬 빠르지만 용량이 작은 캐시 메모리(Cache)를 활용하여 자주 사용하는 데이터를 미리 로드해 둡니다.

1) 참조 지역성(Spatial Locality)의 차이

배열이 연결 리스트보다 성능상 우위에 있는 결정적인 이유는 공간 지역성(Spatial Locality) 때문입니다.
* 배열
  * 요소들이 메모리상에 연속적으로 배치되어 있습니다. CPU가 배열의 한 요소에 접근할 때, 하드웨어는 주변 데이터도 곧 사용될 가능성이 높다고 판단하여 캐시 라인(Cache Line) 단위로 뭉텅이로 캐시에 올립니다. 덕분에 다음 요소에 접근할 때 메모리까지 갈 필요 없이 캐시에서 즉시 데이터를 읽어올 수 있습니다.
* 연결 리스트
  * 데이터들이 메모리 곳곳에 흩어져 있습니다. 다음 노드를 찾으려면 포인터를 따라 매번 불연속적인 메모리 주소로 점프해야 하므로, 원하는 데이터가 캐시에 마침 있는 캐시 적중률(Cache Hit Rate)이 낮고 상대적으로 느린 메인 메모리에 자주 접근해야 합니다.

2) 하드웨어 최적화(Prefetching) 활용

현대 CPU에는 다음에 필요한 데이터를 예측해서 미리 캐시에 로드하는 Prefetching 기능이 탑재되어 있습니다. 배열처럼 주소값이 일정하게 증가하는 선형 구조는 CPU가 다음 데이터를 예측하기 매우 수월하여 이 하드웨어 가속 기능을 아주 잘 활용할 수 있습니다.

# 6. 연결 리스트와 배열 중 어떤 상황에서 무엇을 선택해야 하는가?

앞서 배열의 하드웨어적 성능 이점을 강조했지만, 연결 리스트 역시 특정 시나리오에서는 대체 불가능한 효율성을 보여줍니다. 데이터의 특성과 주요 작업에 따라 적절한 자료구조를 선택해야 합니다.

### 배열을 선택해야 하는 경우
1. 요소들의 참조가 빈번한 경우

1번에서 소개한 것처럼 배열의 접근은 매우 빠릅니다.

2. 스택처럼 배열의 끝에서만 데이터의 삽입/삭제가 일어나는 경우

마지막 요소만 건드리는 경우 배열이 효울적일 수 있습니다.

3. 메모리 효율과 성능이 중요한 경우

5번에서 소개한 것처럼 배열은 성능이 아주 좋습니다.

### 연결 리스트를 선택해야 하는 경우
1. 요소들의 중간에서 삽입/삭제가 빈번한 경우

연결 리스트는 배열과 다르게 앞/뒤의 포인터만 바꿔주면 되는 (`O(1)`) 효율적인 작업입니다.

2. 데이터의 총 크기를 예측할 수 없는 경우

배열은 4번에서 소개한 것처럼 재할당이나 복사비용을 고려해야 하는 반면, 연결 리스트는 필요할 때마다 노드만 추가해주면 됩니다.

3. 대용량 데이터의 빈번한 병합/분할이 필요한 경우

둘 이상의 리스트를 합치거나 자를 떄 포인터만 수정해주면 되므로 매우 효율적입니다.