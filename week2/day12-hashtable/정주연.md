# 해시 테이블(Hash Table)

> 📅 2025.02.24 | 📁 Week 2
> 

---

## 🧠 학습 질문

- [x]  해시 충돌은 왜 불가피한가? (비둘기집 원리)
- [x]  Chaining과 Open Addressing의 장단점은?
- [x]  Linear Probing에서 clustering 문제는 무엇이며 왜 발생하는가?
- [x]  Load Factor가 0.75를 넘으면 왜 성능이 저하되는가?
- [x]  Rehashing은 언제 발생하며 어떻게 동작하는가? 시간복잡도는?
- [x]  해시 테이블의 최악의 경우 시간복잡도가 O(n)인 이유는?

## 해시 충돌은 왜 불가피한가? (비둘기집 원리)

- 해시 함수는 **무한**(또는 매우 많은) 개의 입력값을 유한한 개수의 버킷 인덱스로 매핑함
- 비둘기집 원리(Pigeonhole Principle)
    - **n+1 개 이상의 물건(비둘기)을 n개의 상자(비둘기집)에 넣을 때, 최소한 한 상자에는 2개 이상의 물건이 들어간다는 수학적 원리**
- e.g. 상자 = 버킷 수 m, 물건 = 가능한 key 값들
    - key의 가능한 가짓수 > m  
    ⇒ 서로 다른 두 key가 같은 버킷(같은 해시값)에 매핑될 수밖에 없음 
    ⇒ 충돌은 원리적으로 피할 수 없음
- 좋은 해시함수는 충돌을 줄이는 것임. (없애는 것이 아님)
    
    [](data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==)
    
    [](data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==)
    

## Chaining과 Open Addressing의 장단점은?

### Chaining(Separate Chaining)

- 같은 버킷에 충돌한 원소들을 연결 리스트(또는 동적 배열, 트리 등)로 묶어 관리함
- load factor @ = n/m를 1보다 크게 가져갈 수 있어 메모리 확장 없이도 많은 원소 저장 가능함
- 포인터 구조 때문에 메모리 단편화, 캐시 미스 증가, 리스트 길어지면 탐색 O(α) ~ 최악 O(n)까지 갈 수 있음

### Open Addressing(개방 주소법)

- 충돌 시 다른 빈 버킷을 탐색(probing)하면서 찾아서 그 자리에 넣음
- 모든 원소가 하나의 배열에 있으므로 연속 접근이 가능해 캐시 성능이 좋음, 메모리 오버헤드가 적음
- 대신 load factor를 낮게 유지해야 하고, 삭제 시 단순히 비우면 탐색 경로가 끊기기 때문에 “삭제된 자리”라는 특별한 마킹이 필요

| 방식 | 장점 | 단점 |
| --- | --- | --- |
| Chaining | 구현이 직관적임, 삭제가 쉬움(리스트에서만 제거), load factor > 1 허용 가능함, 충돌이 많아도 삽입이 실패하지 않음 | 포인터/리스트 구조로 인한 메모리 오버헤드, 캐시 친화도가 낮음, 최악 시 한 버킷 리스트 길이 O(n)이 되어 성능 저하 가능 |
| Open Addressing | 모든 데이터를 하나의 배열에 저장 → 메모리 사용 효율적, 캐시 친화도가 좋음(연속된 메모리 접근), 구현에 따라 빠른 평균 성능 | load factor가 높아지면 충돌 시 탐색 길이가 급격히 증가, 삭제 구현이 까다로움(삭제 마커 필요), 테이블이 거의 차면 삽입 실패/성능 붕괴 가능 |

## Linear Probing에서 clustering 문제는 무엇이며 왜 발생하는가?

### Linear Probing

- 충돌 시 `(h(k) + i) mod m` (i = 0,1,2,3,...) 식으로 한 칸씩 순차적으로 다음 버킷을 검사하면서 빈 칸을 찾는 방법
- Clustering(Primary clustering) 문제
    - 연속된 버킷 구간이 차 있는 클러스터가 생기고, 이 구간에 새로운 원소가 계속 붙으면서 덩어리가 더 커지는 현상
    - 이 클러스터를 지나가는 모든 탐색/삽입이 클러스터 길이만큼 연속으로 검사해야 하므로 평균 탐색 길이가 크게 늘어남
- 왜 생김
    - 어떤 해시값 근처에 우연히 충돌이 몇 번 일어나면, 그 주변에 연속된 점유 구간이 만들어짐
    - Linear Probing은 연속해서 한 칸씩만 움직임 → 나중에 다른 키들이 그 범위에 해시될 때, 모두 그 클러스터 뒤쪽에 붙게 됨 → 클러스터가 자라나는 자기 강화 현상이 됨
    - 즉, load factor가 올라갈수록 이 클러스터 효과 때문에 평균 탐색/삽입 횟수가 급격히 증가

## Load Factor가 0.75를 넘으면 왜 성능이 저하되는가?

- load factor *α*=*n*/*m* (n: 원소 수, m: 버킷 수)
- Open Addressing(특히 Linear Probing)의 평균 탐색 길이는 @에 대해 비선형적으로 증가
    - 빈 칸 비율이 줄어들수록 충돌 시 연속으로 차 있는 칸을 만날 확률이 커지고, 한 번 충돌이 나면 빈 칸을 찾을 때까지 더 많은 칸을 봐야 함
- 많은 라이브러리/ 구현들이 0.7~0.8을 넘기면 평균 탐색/ 삽입 비용이 크게 나빠지는 것을 기준으로 삼음
- 특히 Linear Probing에서는 clustering 효과까지 겹쳐서, load factor가 높으면 평균 탐색 길이가 1 / (1 - α) 수준으로 커지는 것으로 알려져 있음
- 따라서 보통 α가 0.7~0.75를 넘으면 rehash(리사이즈)를 해서 테이블을 크게 키워 성능을 유지하려고 함

## Rehashing은 언제 발생하며 어떻게 동작하는가? 시간복잡도는?

- 언제
    - 보통 load factor가 특정 임계값(예: 0.75)을 넘을 때 발생
    - 또는 성능/메모리 정책상, n이 어느 정도 커졌을 때 주기적으로 수행
- 어떻게
    - 더 큰 크기의 새로운 버킷 배열 생성 (e.g. 기존 m의 2배 크기, 또는 다음 소수 크기)
    - 기존 테이블의 모든 원소에 대해 새로운 테이블의 크기에 맞춰 해시를 다시 계산 → 충돌 처리 규칙(Chaining이면 리스트로, Open Addressing이면 probing)을 따라 새 테이블에 한 개씩 다시 삽입
    - old 배열 버리고, new 배열을 현재 테이블로 사용
- 시간복잡도
    - O(n)
        - 한 번 rehash를 수행할 때는 기존 원소 n개를 모두 새로 삽입해야 하므로 단일 rehash 비용은 O(n)
    - O(1)
        - 테이블 크기를 2배씩 늘리면서 “가끔씩만” rehash를 하면, 전체 삽입 n번에 대해 재해싱 비용을 분산시킬 수 있음
        - 평균적으로 각 삽입 연산의 amortized 시간복잡도는 O(1)
            - (가끔 O(n)이 터져도 자주 일어나지 않으므로)

## 해시 테이블의 최악의 경우 시간복잡도가 O(n)인 이유는?

### Chaining의 최악

- 모든 key가 같은 버킷으로 해시된 경우
    - 그 버킷의 연결 리스트 길이가 n이 됨
- 이때 어떤 key를 찾으려면 리스트를 처음부터 끝까지 검색해야 하므로 O(n)

### Open Addressing의 최악

- 테이블이 거의 차 있고, probing 전략 때문에 특정 키를 찾기 위해 배열의 대부분을 검사해야 하는 상황이 발생할 수 있음
- e.g. 거의 모든 칸이 차 있고, 찾는 키가 없거나, 삭제/충돌 패턴 때문에 탐색 경로가 길어져서 최대 n개 버킷을 검사해야 할 수 있음

---

## 📎 참고 자료

## <!-- 공부하면서 참고한 링크를 여기에 추가해주세요 -->

## 💬 토론 포인트

<!-- PR 리뷰 또는 스터디 중 나온 추가 질문이나 논의 사항을 기록해주세요 -->