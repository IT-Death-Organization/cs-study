# Day 12: 해시 테이블(Hash Table)
> 📅 2025.02.24 | 📁 Week 2
---
## 🧠 학습 질문
- [x] 해시 충돌은 왜 불가피한가? (비둘기집 원리)
- [x] Chaining과 Open Addressing의 장단점은?
- [x] Linear Probing에서 clustering 문제는 무엇이며 왜 발생하는가?
- [x] Load Factor가 0.75를 넘으면 왜 성능이 저하되는가?
- [x] Rehashing은 언제 발생하며 어떻게 동작하는가? 시간복잡도는?
- [x] 해시 테이블의 최악의 경우 시간복잡도가 O(n)인 이유는?

---

### 📌 [Q1] 해시 충돌은 왜 불가피한가? (비둘기집 원리)

해시 충돌이란 서로 다른 두 개 이상의 키가 동일한 해시 값(결과값)을 가지는 현상을 말한다.

**해시 충돌의 기본 구조**
: 해시 함수는 데이터의 길이에 상관없이 일정한 크기의 해시값을 반환한다.
- 입력값 A: "Apple" -> 해시 함수 -> 10
- 입력값 B: "Banana" -> 해시 함수 -> 10
이렇게 서로 다른 두 개의 키가 동일한 해시값을 가지는 현상을 해시 충돌이라고 한다.

해시 함수는 키의 범위가 아무리 넓어도, 해시 테이블의 크기(배열의 크기)로 매핑하는 과정에서 필연적으로 충돌이 발생할 수밖에 없다. 왜냐하면 **해시 함수의 결과값 범위는 유한하기 때문**이다.

**비둘기집 원리**
: 비둘기집의 수보다 비둘기의 수가 더 많으면 적어도 한 집에는 두 마리 이상의 비둘기가 들어있어야 한다는 원리 (넣는 개수 > 담을 수 있는 칸 수 -> 반드시 하나 이상이 겹침)

**해시 테이블의 경우**
: key는 이론상 무한 개 가능 (문자열, 숫자 조합 등), 반면 해시값은 보통 고정된 범위이므로 해시 충돌 발생은 불가피하다.


### 📌 [Q2] Chaining과 Open Addressing의 장단점은?

**Chaining(체이닝)**
: **같은 해시값이 나오면, 그 해시값에 해당하는 인덱스에 연결 리스트를 만들어서 데이터를 저장**하는 방식

```
index 3
→ key1 → key7 → key20
```

**장점**
- 구현이 간단하다
- 삭제가 용이하다 (연결 리스트의 노드만 삭제하면 되므로)
- 데이터의 개수가 해시 테이블의 크기보다 많아도 동작한다

**단점**
- 추가 메모리 필요, 메모리 오버헤드 (포인터 저장 공간 필요, 캐시 친화적이지 않음)
- 최악의 경우 시간복잡도가 O(n)이다 (해시가 모두 같은 값을 가질 경우)

**Open Addressing(개방 주소법)**
: **같은 해시값이 나오면(해시 충돌), 그 해시값에 해당하는 인덱스에 빈 공간을 찾아서 데이터를 저장**하는 방식

- Linear Probing
- Quadratic Probing
- Double Hashing

```
index 3 → 충돌
index 4 → 저장
```

**장점**
- 추가 메모리 필요 없음 (배열 안에서만 해결, 메모리 효율 좋음)
- 캐시 친화적 (배열이라서 데이터가 메모리에 연속적으로 저장되어 있어 캐시 효율 좋음)

**단점**
- 로드 팩터에 민감 (0.75 이상이면 성능 저하)
- 삭제가 까다롭다 (그냥 지우면 탐색 경로가 끊김, 삭제된 원소를 표시해야 함)
- 클러스터링 발생 가능성 (연속된 데이터가 생기는 현상)

### 📌 [Q3] Linear Probing에서 clustering 문제는 무엇이며 왜 발생하는가?

Linear Probing은 해시 충돌이 발생하면 **그 다음 인덱스에 데이터를 저장(다음 칸을 순차적으로 탐색)**하는 방식이다.

**클러스터링(Clustering)**
: 해시 충돌로 인해 **연속된 데이터가 생기는 현상(연속된 빈 칸 없이 데이터가 몰려있는 구간이 생김)**

```
[  ][ A ][ B ][ C ][ D ][  ][  ]
        ↑ 하나의 클러스터
```
이렇게 한 덩어리가 생기면 이 구간이 점점 더 커지는 문제가 발생한다. (1차 클러스터링)

```
index 3 → key1
index 4 → key2 (key1과 해시값이 같음)
index 5 → key3 (key1, key2와 해시값이 같음)
```

**발생 원인**
: Linear Probing은 해시 충돌이 발생하면 **바로 다음 칸을 사용하기 때문**이다.
- 어떤 해시값에 충돌 발생 -> 바로 옆 칸에 저장 -> 또 충돌 나면 그 옆 칸에 저장 -> ... -> 계속 옆으로 쌓임
- 이렇게 되면 **연속된 데이터가 생기고, 이 데이터가 점점 더 커지는 문제가 발생**한다.

즉, 특정 구간이 길게 채워지게 되며, 새로운 데이터가 들어올 때 이 데이터가 그 근처의 해시값을 가치면 클러스터링된 긴 구간을 탐색해야 하므로 탐색 시간이 길어진다.

Linear Probing은 **서로 다른 해시값이라도 같은 클러스터에 한 번 들어오면, 동일한 탐색 경로를 공유**한다.
즉, 클러스터가 커질수록 그 근처 해시값을 가진 모든 키가 그 클러스터의 끝까지 탐색해야 하므로 탐색 시간이 길어진다.

**해결책**
- Quadratic Probing
  - +1, +4, +9, +16 ... (제곱으로 증가)
  - 연속 구간 형성을 완화
- Double Hashing
  - 다른 해시 함수로 점프, 두 개의 해시 함수를 사용
  - 탐색 경로 다양화
  - 클러스터 거의 없음

**정리** <br>
Linear Probing에서는 충돌 시 항상 다음 칸을 순차적으로 탐색하기 때문에, 한 번 형성된 연속된 데이터 구간(클러스터)이 점점 커지며 이후 삽입과 탐색 비용을 증가시키는 Primary Clustering 문제가 발생한다. 


### 📌 [Q4] Load Factor가 0.75를 넘으면 왜 성능이 저하되는가?

**Load Factor(적재율)**
: 해시 테이블에 저장된 데이터의 개수(n) / 해시 테이블의 전체 크기(m)
: 0 ~ 1 사이의 값을 가지며, 1에 가까울수록 해시 테이블이 꽉 찼음을 의미한다. (테이블이 얼마나 차 있는가를 나타내는 비율)

**성능 저하 이유**
: Load Factor가 0.75를 넘으면 해시 테이블의 **충돌 확률이 급격히 증가**하기 때문이다.
- 데이터가 많아질수록 해시 테이블의 빈 공간이 줄어든다
- 빈 공간이 줄어들면 충돌이 발생할 확률이 높아진다
- 충돌이 발생하면 해시 테이블의 탐색 시간이 길어진다

로드 팩터가
- 0.5 -> 절반이 비어있음 -> 충돌 적음
- 0.75 -> 25%만 비어있음 -> 충돌 많음
- 1.0 -> 꽉 참 -> 충돌 매우 많음

즉, 빈 칸이 줄어들수록 충돌 확률이 급증하고, 탐색 거리가 증가하며, 클러스터가 커지게 된다.

**정리** <br>
Load Factor가 0.75를 넘으면 해시 테이블의 충돌 확률이 급격히 증가하여 탐색 시간이 길어지므로 성능이 저하된다. 


### 📌 [Q5] Rehashing은 언제 발생하며 어떻게 동작하는가? 시간복잡도는?

**Rehashing(리해싱)**
: 해시 테이블의 크기를 늘린 뒤, 기존 모든 데이터를 다시 해시해서 재배치하는 과정

**발생 시점**
- Load Factor가 특정 임계값(보통 0.75)을 초과할 때
- 데이터가 너무 많아져서 충돌 확률이 높아질 때

**동작 방식**
1. **더 큰 새로운 해시 테이블 생성**
   - 기존 테이블보다 더 큰 크기(보통 2배)의 새로운 배열 생성

2. **기존 데이터 재해싱(재삽입)**
   - 기존 테이블의 모든 데이터를 새로운 테이블로 이동
   - 이때, **새로운 테이블의 크기에 맞춰 해시값을 다시 계산**
      - 단순 복사 아님! 해시값을 다시 계산해야 함, 안 그러면 값이 달라질 수 있음

**시간복잡도**
- **O(n)** -> 모든 데이터를 새로운 테이블로 이동해야 하므로 (한 번의 Rehasing 비용)
- 단, 해시는 **amortized O(1)**이다 -> 테이블은 보통 2배씩 증가하고 Rehashing은 드물게 발생하기 때문, 결과적으로 전체 삽입 n번 동안 총 재배치 비용은 O(n), 따라서 평균 삽입 시간은 O(1)

**정리** <br>
Rehashing은 Load Factor가 임계값(보통 0.75)을 초과할 때 발생하며, 해시 테이블의 크기를 보통 2배로 확장한 뒤 기존 모든 원소를 새 배열에 다시 해시하여 재배치하는 과정입니다. 한 번의 Rehash는 O(n)이지만, 테이블이 기하급수적으로 증가하므로 삽입 연산의 Amortized 시간복잡도는 O(1)입니다.


### 📌 [Q6] 해시 테이블의 최악의 경우 시간복잡도가 O(n)인 이유는?

해시 테이블은 평균적으로 삽입/탐색/삭제 연산은 O(1)이지만, 최악의 경우 O(n)이다.

**최악의 경우**
: **모든 키가 동일한 해시값**을 가질 때
```
h(k1) = h(k2) = h(k3) = ... = h(kn)
```

**동작 방식**
1. **모든 데이터가 동일한 해시값**을 가짐
2. **모든 데이터가 동일한 인덱스**에 저장됨
3. **모든 데이터가 동일한 연결 리스트**에 저장됨 (Chaining의 경우)
4. **모든 데이터가 동일한 클러스터**에 저장됨 (Open Addressing의 경우)

**시간복잡도**
- **O(n)** -> 모든 데이터를 순차적으로 탐색해야 하므로

**정리** <br>
해시 테이블의 최악의 경우(비효율적인 해시 함수 등) 시간복잡도가 O(n)인 이유는 모든 데이터가 동일한 해시값을 가질 때 발생하며, 이때는 모든 데이터가 동일한 인덱스에 저장되어 연결 리스트의 모든 원소를 순차적으로 탐색해야 하기 때문입니다. (Chaining의 경우 연결 리스트 탐색으로 O(n), Open Addressing의 경우 연속된 클러스터 탐색으로 O(n))

---
## 📎 참고 자료
<!-- 공부하면서 참고한 링크를 여기에 추가해주세요 -->
---
## 💬 토론 포인트
<!-- PR 리뷰 또는 스터디 중 나온 추가 질문이나 논의 사항을 기록해주세요 -->
